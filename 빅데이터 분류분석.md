#### 지도학습: 데이터의 측정된 특징과 레이블 사이의 관계를 모델링 하는 것

#### 분류 분석: 지도학습에 포함되고 레이블이 이산적인 범주형인 경우

##### 이산적인 범주형 레이블
> 어떤 지수를 연속적인 숫자가 아니라  2개의 등급으로 표현
데이터에 따라 등급의 숫자는 달라질 수 있음

> 레이블이 연속적인 데이터일지라도 특정값을 기준으로 몇 개의 구간으로 구분하면
범주형 레이블로 취급할 수도 있음

분류 모델의 정확도는 직선이 어느 치에서 어느 방향으로 그려지는가에 따라 달라짐

### 모수
모델의 모수: 직선의 위치와 방향을 설명할 수 있는 특정 숫자

머신러닝에서 학습 또는 훈련이라고 부르는 과정은 데이터로부터 이 모수를 찾아내는 것

데이터를 학습하여 모델의 모수를 찾는 과정: 적합, 영어로는 fitting

모델 적용: 학습한 모델을 이용하여 레이블이 없는 새 데이터를 분류하는 것


레이블된 데이터가 축적될수록 머신러닝의 강력한 기능이 더 잘 발휘될 수 있음

빅데이터 환경에서 머신러닝이 막강한 도구로 유용성을 인정받고 있는 이유

Scikit-Learn API는 모든 머신러닝 기법에 대해 공통적인 사용법을 제공하므로
 분류 분석에도 동일한 단계로 진행

### Scikit-Learn API 사용 단계
> 1. Scikit-Learn API에서 적절한 추정기 클래스를 임포트 해서 사용하고자 하는 모델
선택
2. 클래스로부터 인스턴스를 생성하고 초모수 설정
3.데이터를 특징 배열과 대상 배열로 준비
4. 모델 인스턴스의 fit()메소드를 호출해서 데이터 학습
5.정확도 확인 후 새로운 데이터에 모델 적용

### 분류 모델의 정확도
Scikit-Learn에서 제공하는 accuracy_score 유틸리티를 사용

accuracy_score 유틸리티: 두 배열 사이에 서로 일치하는 요소의 비율을 계산하는 기능

초모수: 학습을 통해 추정되지 않는 모델 모수

### 성공적인 지도학습
> 새로운 데이터에 대해 정확도가 높은 모델을 찾아내는 것

#### 이론적인 모델 검증 방법:
> 1. 모델과 그 모델의 초모수를 선택한 후, 훈련 데이터로 모델을 훈련
2. 훈련된 모델을 적용하여 계산한 예측값을 실제값과 비교해서 이 모델이 얼마나
 효과적인지 추정

머신러닝의 본래 목적: 훈련하지 않은 데이터에 대해 예측력이 우수하도록 하는 것

머신러닝을 테스트 할 때는 올바른 방식의 검증 방식이 필요

### 모델의 성능을 제대로 평가하려면
 > 훈련에 사용한 데이터와 검증에 사용하는 데이터를 분리해야 함
충분히 많은 양의 데이터를 확보할 수 있다면, 학습을 시작하기 전에 데이터의 일부를
훈련 데이터로 사용하고 나머지를 검증 데이터로 사용하도록 분할할 수 있음

>이 작업에는 Scikit-learn의 train_test_split 유틸리티를 사용

### 교차 검증
교차검증 방법: 데이터의 양이 충분하지 않은 경우 사용하는 방법

##### 교차검증의 기본 원리: 데이터를 분할하여 훈련데이터와 검증데이터로 역할을
 교대로 사용하는 것

데이터를 절반씩 나누어 절반은 훈련데이터로 나머지 절반은 검증데이터로 사용하고,
 서로 역할을 바꾸어 훈련과 검증을 반복 실시하는 방식

Scikit-Learn에는 교차검증을 편리하게 수행할 수 있도록  cross_val_score라는 기능이
 있음
교차 검증을 몇 겹으로 할지는 cv 인수의 값을 변경하여 설정할 수 있음

Cross_val_score 함수의 반환 값은 넘파이 객체 배열이므로 넘파이 함수 mean()을
 사용하여 평균을 계산할 수 있음

단일 관측치 제거 방식(leave-one-out) 교차 검증: 데이터의 수가 극도로 적은 경우에는
 1개의 데이터만을 검증데이터로 사용할 수도 있는데, 이 경우에는 전체 데이터의 수
  만큼 교차 검증을 반복

#### 베이즈 분류 개념
베이즈 분류에서는 관측된 특징, 즉 feature가 주어졌을 때 레이블(label)의 확률을
 구하는 데 관심이 있으며, 이를 조건부 확률로 표현할 수 있는데 이 확률값을 레이블의
  사후 확률이라고 함

* 나이브 베이즈 기법: 계산이 빠르고 초모수 설정이 간단하여 다른 어떤 모델 보다 먼저
 데이터에 적용해 볼 수 있는 모델

확률 표현의 장점: 확률적으로 표시하여 분류 결과가 명확한 점과 애매한 점을 구분할 수
있다는 것
